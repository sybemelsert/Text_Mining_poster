{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4171a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22302df91fbf47c28d5d94102896996a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   7%|6         | 115M/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4949f3963a0e450fabedbe7121e58144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e46b1d930bb4e4eb13a644736fdbcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f54e8949674c4792344bef5f63b0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83de3098aaf4b1f8d904ee490dbc914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence   topic predicted_topic\n",
      "0  The stadium was alive with the roar of the cro...  sports          sports\n",
      "1  That last-minute goal had me jumping out of my...  sports          sports\n",
      "2  I couldnâ€™t put the book down; it swept me into...    book            book\n",
      "3  The story had its moments, though some parts f...    book           movie\n",
      "4  I enjoyed the way the timelines shifted, even ...    book           movie\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        book      1.000     0.500     0.667         6\n",
      "       movie      0.667     1.000     0.800         6\n",
      "      sports      1.000     1.000     1.000         6\n",
      "\n",
      "    accuracy                          0.833        18\n",
      "   macro avg      0.889     0.833     0.822        18\n",
      "weighted avg      0.889     0.833     0.822        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load test data\n",
    "df = pd.read_csv(\"sentiment-topic-test.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Define the candidate topic labels (from your test set)\n",
    "candidate_labels = [\"sports\", \"book\", \"movie\"]\n",
    "\n",
    "# Load the zero-shot classification model\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Store predictions\n",
    "predicted_topics = []\n",
    "\n",
    "# Classify each sentence\n",
    "for sentence in df[\"sentence\"]:\n",
    "    result = classifier(sentence, candidate_labels)\n",
    "    predicted_topics.append(result[\"labels\"][0])  # Take the top predicted label\n",
    "\n",
    "# Add predictions to the DataFrame\n",
    "df[\"predicted_topic\"] = predicted_topics\n",
    "\n",
    "# Show a few results\n",
    "print(df[[\"sentence\", \"topic\", \"predicted_topic\"]].head())\n",
    "\n",
    "# Evaluate the predictions\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(df[\"topic\"], df[\"predicted_topic\"], digits=3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text_mining_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
