{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "313d1247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.00      0.00      0.00         0\n",
      "        DATE       0.00      0.00      0.00         0\n",
      "       EVENT       0.00      0.00      0.00         0\n",
      "         GPE       0.00      0.00      0.00         0\n",
      "    LOCATION       0.00      0.00      0.00         3\n",
      "         ORG       0.50      0.50      0.50         8\n",
      "      PERSON       0.58      0.58      0.58        12\n",
      " WORK_OF_ART       0.33      0.17      0.22         6\n",
      "\n",
      "   micro avg       0.38      0.41      0.39        29\n",
      "   macro avg       0.18      0.16      0.16        29\n",
      "weighted avg       0.45      0.41      0.43        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jespe\\anaconda3\\envs\\Text_mining_3_12\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jespe\\anaconda3\\envs\\Text_mining_3_12\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from seqeval.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load a small English NER model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the test data from a TSV file (tab-separated values)\n",
    "df = pd.read_csv(\"NER-test.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Group tokens by sentence ID to rebuild full sentences\n",
    "sentences = defaultdict(list)\n",
    "for _, row in df.iterrows():\n",
    "    sentences[row[\"sentence_id\"]].append((row[\"token\"], row[\"BIO_NER_tag\"]))\n",
    "\n",
    "# Lists to store the true (gold) and predicted BIO tags\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "# Process each sentence\n",
    "for tokens in sentences.values():\n",
    "    # Separate the tokens and the gold BIO tags\n",
    "    tokens_list = [t for t, _ in tokens]\n",
    "    gold_tags = [t for _, t in tokens]\n",
    "    true_labels.append(gold_tags)\n",
    "\n",
    "    # Join tokens into a single string for spaCy processing\n",
    "    text = \" \".join(tokens_list)\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Start with a list of \"O\" tags (meaning no entity)\n",
    "    pred_tags = [\"O\"] * len(tokens_list)\n",
    "\n",
    "    # For each named entity predicted by spaCy\n",
    "    for ent in doc.ents:\n",
    "        # Split the entity text into individual words (tokens)\n",
    "        ent_tokens = ent.text.split()\n",
    "\n",
    "        # Try to find the position of this entity in our token list\n",
    "        for i in range(len(tokens_list)):\n",
    "            # Check if a sequence in the token list matches the entity tokens\n",
    "            if tokens_list[i:i+len(ent_tokens)] == ent_tokens:\n",
    "                # Mark the first token of the entity with \"B-<LABEL>\"\n",
    "                pred_tags[i] = \"B-\" + ent.label_\n",
    "                # Mark the rest with \"I-<LABEL>\"\n",
    "                for j in range(1, len(ent_tokens)):\n",
    "                    pred_tags[i + j] = \"I-\" + ent.label_\n",
    "                break  # Stop searching after the first match\n",
    "\n",
    "    # Add the predicted tags for this sentence\n",
    "    pred_labels.append(pred_tags)\n",
    "\n",
    "# Print a classification report comparing gold and predicted tags\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text_mining_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
